{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    " #from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Lambda, Multiply\n",
    "from tensorflow.keras import backend as K\n",
    "import cv2, numpy as np\n",
    "import glob\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.activations import relu \n",
    "import keras as keras\n",
    "from tensorflow.keras.models import Model,load_model\n",
    "from tensorflow.keras.layers import  Input,Conv2D,BatchNormalization,Activation,Lambda,Subtract,concatenate,Add,add,Reshape\n",
    "\n",
    "from tensorflow.keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose,DepthwiseConv2D,Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.layers import  Layer,Activation, Lambda, MaxPooling2D, UpSampling2D, Conv2DTranspose, SpatialDropout2D\n",
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import EarlyStopping \n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from  sklearn.model_selection import train_test_split\n",
    "\n",
    "#from tensorflow.python import debug as tf_debug\n",
    "import imageio\n",
    "import glob\n",
    "from skimage import transform as tf\n",
    "from tensorflow.keras.losses import mse, binary_crossentropy\n",
    "\n",
    "\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as plt_img\n",
    "import scipy\n",
    "import scipy\n",
    "import skimage\n",
    "import re\n",
    "#import LRFinder\n",
    "import math as m\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler \n",
    "from tensorflow.keras import backend as K\n",
    "from pathlib import Path\n",
    "from keras import objectives\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "import numpy as np\n",
    " \n",
    "from keras import backend as K\n",
    "from skimage.measure import compare_ssim, compare_psnr\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "tf.random.Generator = None \n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.datasets import  mnist, fashion_mnist\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from scipy.fftpack import dct, idct\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# load MNIST dataset\n",
    "(x_train, y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "# from sparse label to categorical\n",
    "num_labels = len(np.unique(y_train))\n",
    "y_train = to_categorical(y_train)\n",
    "Y_test = to_categorical(Y_test)\n",
    "\n",
    "# reshape and normalize input images\n",
    "image_size = x_train.shape[1]\n",
    "x_train = np.reshape(x_train,[-1, image_size, image_size, 1])\n",
    "X_test = np.reshape(X_test,[-1, image_size, image_size, 1])\n",
    "x_train = x_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "x_val=X_test[:8000]\n",
    "y_val=Y_test[:8000]\n",
    "\n",
    "x_test=X_test[8000:]\n",
    "y_test=Y_test[8000:]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network parameters\n",
    "input_shape = (image_size, image_size, 1)\n",
    "batch_size = 128\n",
    "kernel_size = 3\n",
    "filters = 64\n",
    "dropout = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                5770      \n",
      "=================================================================\n",
      "Total params: 80,266\n",
      "Trainable params: 80,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    " \n",
    "inputs = Input(shape=input_shape)\n",
    "y = Conv2D(filters=filters,kernel_size=kernel_size,activation='relu')(inputs)\n",
    "y = MaxPooling2D()(y)\n",
    "y = Conv2D(filters=filters,kernel_size=kernel_size,activation='relu')(y)\n",
    "y = MaxPooling2D()(y)\n",
    "y = Conv2D(filters=filters,kernel_size=kernel_size,activation='relu')(y)\n",
    " \n",
    "y = Flatten()(y)\n",
    " \n",
    "y = Dropout(dropout)(y)\n",
    "outputs = Dense(num_labels, activation='softmax')(y)\n",
    "\n",
    " \n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    " \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "permt = [1,2,3]\n",
    "subbands = [\"d\", \"h\", \"v\"]\n",
    "img_size=28\n",
    "n_channels=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def applyDCTPermutation(data, permutation,n_channels,img_size):\n",
    "\n",
    "    n = data.shape[0]\n",
    "\n",
    "    for i in range(n):\n",
    "        for c in range(n_channels):\n",
    "            xdct = dct(dct(data[i, :, :, c]).T)\n",
    "            xdct = applySignPermutation(xdct, permutation,img_size)\n",
    "            data[i, :, :, c] = idct(idct(xdct).T)\n",
    "            nrm = np.sqrt(np.sum(data[i, :, :, c]**2))\n",
    "            data[i, :, :, c] /= nrm\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def applySignPermutation(data, permutation,img_size):\n",
    "    dim = data.shape\n",
    "\n",
    "    data = np.reshape(data, (-1, img_size ** 2))\n",
    "    data = np.multiply(data, np.tile(permutation, (data.shape[0], 1)))\n",
    "\n",
    "    return np.reshape(data, dim)\n",
    "\n",
    "\n",
    "def signPermutation(is_zero, subband , img_size):\n",
    "        if is_zero:\n",
    "            permutation = np.zeros((1, image_size ** 2))\n",
    "        else:\n",
    "            permutation = np.random.normal(size= image_size ** 2)\n",
    "            permutation[permutation >= 0] = 1\n",
    "            permutation[permutation != 1] = -1\n",
    "\n",
    "        if subband == \"d\":  # D - diagonal\n",
    "            permutation = np.reshape(permutation, ( image_size,  image_size))\n",
    "            permutation[0: image_size // 2, :] = 1\n",
    "            permutation[:, 0: image_size // 2] = 1\n",
    "\n",
    "        elif subband == \"v\":  # V - vertical\n",
    "            permutation = np.reshape(permutation, ( image_size,  image_size))\n",
    "            permutation[:, 0: image_size // 2] = 1\n",
    "            permutation[ image_size // 2: image_size, :] = 1\n",
    "\n",
    "        elif subband == \"h\":  # H - horizontal\n",
    "            permutation = np.reshape(permutation, ( image_size,  image_size))\n",
    "            permutation[0: image_size // 2, :] = 1\n",
    "            permutation[:,  image_size // 2: image_size] = 1\n",
    "\n",
    "        elif subband == \"dhv\":\n",
    "            permutation = np.reshape(permutation, ( image_size, image_size))\n",
    "            permutation[0: image_size // 2, 0: image_size // 2] = 1\n",
    "\n",
    "        return np.reshape(permutation, ( image_size ** 2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 2000 samples\n",
      "Epoch 1/4\n",
      "59264/60000 [============================>.] - ETA: 0s - loss: 0.4350 - accuracy: 0.8632\n",
      "Epoch 00001: val_loss improved from inf to 0.05885, saving model to 1_d.hdf5\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.4314 - accuracy: 0.8643 - val_loss: 0.0589 - val_accuracy: 0.9835\n",
      "Epoch 2/4\n",
      "59136/60000 [============================>.] - ETA: 0s - loss: 0.1103 - accuracy: 0.9659\n",
      "Epoch 00002: val_loss improved from 0.05885 to 0.03465, saving model to 1_d.hdf5\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.1102 - accuracy: 0.9660 - val_loss: 0.0347 - val_accuracy: 0.9890\n",
      "Epoch 3/4\n",
      "59008/60000 [============================>.] - ETA: 0s - loss: 0.0773 - accuracy: 0.9762\n",
      "Epoch 00003: val_loss improved from 0.03465 to 0.02470, saving model to 1_d.hdf5\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0768 - accuracy: 0.9764 - val_loss: 0.0247 - val_accuracy: 0.9915\n",
      "Epoch 4/4\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0617 - accuracy: 0.9811\n",
      "Epoch 00004: val_loss improved from 0.02470 to 0.02240, saving model to 1_d.hdf5\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0616 - accuracy: 0.9811 - val_loss: 0.0224 - val_accuracy: 0.9930\n",
      "Train on 60000 samples, validate on 2000 samples\n",
      "Epoch 1/4\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0545 - accuracy: 0.9835\n",
      "Epoch 00001: val_loss improved from inf to 0.01912, saving model to 1_h.hdf5\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.0546 - accuracy: 0.9834 - val_loss: 0.0191 - val_accuracy: 0.9925\n",
      "Epoch 2/4\n",
      "58880/60000 [============================>.] - ETA: 0s - loss: 0.0470 - accuracy: 0.9852\n",
      "Epoch 00002: val_loss did not improve from 0.01912\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.0470 - accuracy: 0.9852 - val_loss: 0.0219 - val_accuracy: 0.9925\n",
      "Epoch 3/4\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.0410 - accuracy: 0.9871\n",
      "Epoch 00003: val_loss improved from 0.01912 to 0.01740, saving model to 1_h.hdf5\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0411 - accuracy: 0.9871 - val_loss: 0.0174 - val_accuracy: 0.9950\n",
      "Epoch 4/4\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0375 - accuracy: 0.9883\n",
      "Epoch 00004: val_loss improved from 0.01740 to 0.01500, saving model to 1_h.hdf5\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0376 - accuracy: 0.9883 - val_loss: 0.0150 - val_accuracy: 0.9955\n",
      "Train on 60000 samples, validate on 2000 samples\n",
      "Epoch 1/4\n",
      "59520/60000 [============================>.] - ETA: 0s - loss: 0.0391 - accuracy: 0.9879\n",
      "Epoch 00001: val_loss improved from inf to 0.01508, saving model to 1_v.hdf5\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.0391 - accuracy: 0.9880 - val_loss: 0.0151 - val_accuracy: 0.9940\n",
      "Epoch 2/4\n",
      "59008/60000 [============================>.] - ETA: 0s - loss: 0.0352 - accuracy: 0.9891\n",
      "Epoch 00002: val_loss improved from 0.01508 to 0.01344, saving model to 1_v.hdf5\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0352 - accuracy: 0.9891 - val_loss: 0.0134 - val_accuracy: 0.9955\n",
      "Epoch 3/4\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0323 - accuracy: 0.9895\n",
      "Epoch 00003: val_loss did not improve from 0.01344\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0324 - accuracy: 0.9895 - val_loss: 0.0138 - val_accuracy: 0.9950\n",
      "Epoch 4/4\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0283 - accuracy: 0.9913\n",
      "Epoch 00004: val_loss did not improve from 0.01344\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0284 - accuracy: 0.9913 - val_loss: 0.0186 - val_accuracy: 0.9935\n",
      "Train on 60000 samples, validate on 2000 samples\n",
      "Epoch 1/4\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0261 - accuracy: 0.9921\n",
      "Epoch 00001: val_loss improved from inf to 0.01626, saving model to 2_d.hdf5\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.0260 - accuracy: 0.9920 - val_loss: 0.0163 - val_accuracy: 0.9945\n",
      "Epoch 2/4\n",
      "59008/60000 [============================>.] - ETA: 0s - loss: 0.0250 - accuracy: 0.9918\n",
      "Epoch 00002: val_loss improved from 0.01626 to 0.01610, saving model to 2_d.hdf5\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.0250 - accuracy: 0.9919 - val_loss: 0.0161 - val_accuracy: 0.9950\n",
      "Epoch 3/4\n",
      "58752/60000 [============================>.] - ETA: 0s - loss: 0.0229 - accuracy: 0.9929\n",
      "Epoch 00003: val_loss improved from 0.01610 to 0.01173, saving model to 2_d.hdf5\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.0228 - accuracy: 0.9929 - val_loss: 0.0117 - val_accuracy: 0.9970\n",
      "Epoch 4/4\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.0218 - accuracy: 0.9929\n",
      "Epoch 00004: val_loss did not improve from 0.01173\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.0217 - accuracy: 0.9930 - val_loss: 0.0131 - val_accuracy: 0.9960\n",
      "Train on 60000 samples, validate on 2000 samples\n",
      "Epoch 1/4\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.0213 - accuracy: 0.9935\n",
      "Epoch 00001: val_loss improved from inf to 0.01511, saving model to 2_h.hdf5\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.0213 - accuracy: 0.9935 - val_loss: 0.0151 - val_accuracy: 0.9945\n",
      "Epoch 2/4\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0208 - accuracy: 0.9935\n",
      "Epoch 00002: val_loss improved from 0.01511 to 0.00995, saving model to 2_h.hdf5\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0208 - accuracy: 0.9935 - val_loss: 0.0100 - val_accuracy: 0.9970\n",
      "Epoch 3/4\n",
      "59008/60000 [============================>.] - ETA: 0s - loss: 0.0199 - accuracy: 0.9933\n",
      "Epoch 00003: val_loss did not improve from 0.00995\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0198 - accuracy: 0.9933 - val_loss: 0.0145 - val_accuracy: 0.9955\n",
      "Epoch 4/4\n",
      "58880/60000 [============================>.] - ETA: 0s - loss: 0.0172 - accuracy: 0.9941\n",
      "Epoch 00004: val_loss did not improve from 0.00995\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0172 - accuracy: 0.9942 - val_loss: 0.0111 - val_accuracy: 0.9965\n",
      "Train on 60000 samples, validate on 2000 samples\n",
      "Epoch 1/4\n",
      "58880/60000 [============================>.] - ETA: 0s - loss: 0.0187 - accuracy: 0.9938\n",
      "Epoch 00001: val_loss improved from inf to 0.01436, saving model to 2_v.hdf5\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.0185 - accuracy: 0.9938 - val_loss: 0.0144 - val_accuracy: 0.9965\n",
      "Epoch 2/4\n",
      "59520/60000 [============================>.] - ETA: 0s - loss: 0.0173 - accuracy: 0.9940\n",
      "Epoch 00002: val_loss did not improve from 0.01436\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0175 - accuracy: 0.9940 - val_loss: 0.0148 - val_accuracy: 0.9955\n",
      "Epoch 3/4\n",
      "59136/60000 [============================>.] - ETA: 0s - loss: 0.0147 - accuracy: 0.9950\n",
      "Epoch 00003: val_loss did not improve from 0.01436\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0146 - accuracy: 0.9951 - val_loss: 0.0167 - val_accuracy: 0.9960\n",
      "Epoch 4/4\n",
      "58880/60000 [============================>.] - ETA: 0s - loss: 0.0143 - accuracy: 0.9951\n",
      "Epoch 00004: val_loss improved from 0.01436 to 0.01383, saving model to 2_v.hdf5\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0143 - accuracy: 0.9952 - val_loss: 0.0138 - val_accuracy: 0.9950\n",
      "Train on 60000 samples, validate on 2000 samples\n",
      "Epoch 1/4\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0142 - accuracy: 0.9952\n",
      "Epoch 00001: val_loss improved from inf to 0.01178, saving model to 3_d.hdf5\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.0142 - accuracy: 0.9952 - val_loss: 0.0118 - val_accuracy: 0.9980\n",
      "Epoch 2/4\n",
      "58752/60000 [============================>.] - ETA: 0s - loss: 0.0130 - accuracy: 0.9956\n",
      "Epoch 00002: val_loss did not improve from 0.01178\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.0129 - accuracy: 0.9956 - val_loss: 0.0131 - val_accuracy: 0.9960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/4\n",
      "58880/60000 [============================>.] - ETA: 0s - loss: 0.0127 - accuracy: 0.9959\n",
      "Epoch 00003: val_loss did not improve from 0.01178\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0126 - accuracy: 0.9959 - val_loss: 0.0146 - val_accuracy: 0.9970\n",
      "Epoch 4/4\n",
      "59520/60000 [============================>.] - ETA: 0s - loss: 0.0127 - accuracy: 0.9956\n",
      "Epoch 00004: val_loss did not improve from 0.01178\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0127 - accuracy: 0.9956 - val_loss: 0.0126 - val_accuracy: 0.9960\n",
      "Train on 60000 samples, validate on 2000 samples\n",
      "Epoch 1/4\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0123 - accuracy: 0.9956\n",
      "Epoch 00001: val_loss improved from inf to 0.01366, saving model to 3_h.hdf5\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.0123 - accuracy: 0.9956 - val_loss: 0.0137 - val_accuracy: 0.9960\n",
      "Epoch 2/4\n",
      "58752/60000 [============================>.] - ETA: 0s - loss: 0.0109 - accuracy: 0.9959\n",
      "Epoch 00002: val_loss improved from 0.01366 to 0.01237, saving model to 3_h.hdf5\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0109 - accuracy: 0.9959 - val_loss: 0.0124 - val_accuracy: 0.9970\n",
      "Epoch 3/4\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0115 - accuracy: 0.9962\n",
      "Epoch 00003: val_loss did not improve from 0.01237\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.0114 - accuracy: 0.9962 - val_loss: 0.0156 - val_accuracy: 0.9955\n",
      "Epoch 4/4\n",
      "58752/60000 [============================>.] - ETA: 0s - loss: 0.0104 - accuracy: 0.9962\n",
      "Epoch 00004: val_loss did not improve from 0.01237\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.0104 - accuracy: 0.9962 - val_loss: 0.0149 - val_accuracy: 0.9965\n",
      "Train on 60000 samples, validate on 2000 samples\n",
      "Epoch 1/4\n",
      "59392/60000 [============================>.] - ETA: 0s - loss: 0.0118 - accuracy: 0.9959\n",
      "Epoch 00001: val_loss improved from inf to 0.01183, saving model to 3_v.hdf5\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0118 - accuracy: 0.9959 - val_loss: 0.0118 - val_accuracy: 0.9970\n",
      "Epoch 2/4\n",
      "59136/60000 [============================>.] - ETA: 0s - loss: 0.0102 - accuracy: 0.9964\n",
      "Epoch 00002: val_loss did not improve from 0.01183\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0102 - accuracy: 0.9964 - val_loss: 0.0136 - val_accuracy: 0.9975\n",
      "Epoch 3/4\n",
      "58752/60000 [============================>.] - ETA: 0s - loss: 0.0097 - accuracy: 0.9964\n",
      "Epoch 00003: val_loss did not improve from 0.01183\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.0096 - accuracy: 0.9965 - val_loss: 0.0123 - val_accuracy: 0.9975\n",
      "Epoch 4/4\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.0108 - accuracy: 0.9964\n",
      "Epoch 00004: val_loss improved from 0.01183 to 0.00923, saving model to 3_v.hdf5\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.0092 - val_accuracy: 0.9965\n"
     ]
    }
   ],
   "source": [
    "is_zero=False\n",
    "\n",
    "for p in permt:\n",
    "    for subband in subbands:\n",
    "        filepath=str(p) +'_'+ str(subband)+\".hdf5\"\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    " \n",
    "        \n",
    "        permutation =  signPermutation(is_zero,subband,img_size)\n",
    "        x_train = applyDCTPermutation(x_train, permutation,n_channels,img_size)\n",
    "        x_test = applyDCTPermutation(x_test, permutation,n_channels,img_size)\n",
    "        model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "        model.fit(x_train,y_train,validation_data=(x_test, y_test),epochs=4,batch_size=batch_size, callbacks = [checkpoint])\n",
    "     \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Phase\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def impr(im):\n",
    "    ar=[]\n",
    "    img = np.asarray(im) \n",
    "    ar.append(img) \n",
    "    ay = np.asarray(ar)\n",
    "    return ay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=3449\n",
    "# original_label\n",
    "\n",
    "y_val[i].argmax(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b8be2cd8c8>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# original test image\n",
    "\n",
    "plt.imshow(x_val[i],cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml=[]\n",
    "for p in permt:\n",
    "    for subband in subbands:\n",
    "        model.load_weights(str(p) +'_'+ str(subband)+\".hdf5\")\n",
    "        img=x_val[i]\n",
    "        im=impr(img)\n",
    "        permutation =  signPermutation(is_zero,subband,img_size)\n",
    "        im = applyDCTPermutation(im, permutation,n_channels,img_size)\n",
    "        pr=model.predict(im)\n",
    "        ml.append(pr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3]], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction for all permutation_/_subbands \n",
    "\n",
    "mr=np.asarray(ml)\n",
    "mr.argmax(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Bdeep] *",
   "language": "python",
   "name": "conda-env-Bdeep-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
